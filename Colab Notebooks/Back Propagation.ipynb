{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN3jq3eoZkzbQL4Vv6fyhUV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":26,"metadata":{"id":"eOXcfFRPQu_v","executionInfo":{"status":"ok","timestamp":1756495302388,"user_tz":-330,"elapsed":78,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim"]},{"cell_type":"code","source":["# 1. Define a simple model and optimizer\n","model = nn.Linear(2, 1) # A linear model\n","optimizer = optim.SGD(model.parameters(), lr=0.01)"],"metadata":{"id":"j5lwoRrkQvxI","executionInfo":{"status":"ok","timestamp":1756495302394,"user_tz":-330,"elapsed":5,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["# 2. Simulate a training step with a single data point\n","inputs = torch.randn(1, 2)\n","labels = torch.randn(1, 1)"],"metadata":{"id":"NcNimJ1FQ0EZ","executionInfo":{"status":"ok","timestamp":1756495369451,"user_tz":-330,"elapsed":40,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["inputs, labels"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kxM-xUJgR98b","executionInfo":{"status":"ok","timestamp":1756495370482,"user_tz":-330,"elapsed":14,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}},"outputId":"839fc875-8468-4088-959a-91929bbab327"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[ 0.6041, -1.3248]]), tensor([[0.5254]]))"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["# ----- Training loop steps -----\n","optimizer.zero_grad()\n","outputs = model(inputs)\n","loss = (outputs - labels)**2\n","loss.backward() # Calculates gradients and stores in model.parameters().grad\n"],"metadata":{"id":"yZ0CBlcrQ5Sf","executionInfo":{"status":"ok","timestamp":1756495379385,"user_tz":-330,"elapsed":15,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["outputs, loss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s-ivkv2ISnsT","executionInfo":{"status":"ok","timestamp":1756495630597,"user_tz":-330,"elapsed":9,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}},"outputId":"18995b50-d051-431f-c8e6-9a01f7eb006f"},"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[1.0452]], grad_fn=<AddmmBackward0>),\n"," tensor([[0.2702]], grad_fn=<PowBackward0>))"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["# Inspect gradients (for demonstration)\n","print(\"Gradient of weight:\", model.weight.grad)\n","print(\"Gradient of bias:\", model.bias.grad)\n","\n","optimizer.step() # Updates parameters using the calculated gradients"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fsuq4tCvQ_Us","executionInfo":{"status":"ok","timestamp":1756495380194,"user_tz":-330,"elapsed":4,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}},"outputId":"454ebf95-63c4-416f-c356-278c4e2f4be0"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Gradient of weight: tensor([[ 0.6280, -1.3773]])\n","Gradient of bias: tensor([1.0396])\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"41mKLKB7RDBX","executionInfo":{"status":"ok","timestamp":1756495302420,"user_tz":-330,"elapsed":13,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}}},"execution_count":30,"outputs":[]}]}