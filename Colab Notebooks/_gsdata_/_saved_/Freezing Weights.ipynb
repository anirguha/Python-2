{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1hQOJz5-ZV-oGrz70fDTyFKE2k5uf6Tlu","timestamp":1757264373914},{"file_id":"1kYHbsa9tf0ywRAibD8gnpsUwEngxrG92","timestamp":1619327650469},{"file_id":"1Zh1wPFY2Qqr3Mn9Qr3DyhMinJTjIk1Hz","timestamp":1618937769616},{"file_id":"1zk0u7ZpzZ38GbX9ExPJRi-V2gSHX3DZX","timestamp":1618934353597},{"file_id":"13SFr82QoaJr9so_o_rSl1L9WbOMXpUSR","timestamp":1618861176115},{"file_id":"1FcEBC0NAESIlHQkv6_85R-XDUKGE8XbM","timestamp":1618848117844},{"file_id":"1qKgZ8kVcqNgwtBzHbWq5yJH_HqI6DxWW","timestamp":1617803880910},{"file_id":"15cpyHkJ435B4MqbyGjAH1poN4nCy_DE4","timestamp":1617737766196},{"file_id":"1OLuWuaFu0hcFgkQ2hh5BqbRuqUZD7XcQ","timestamp":1617734878578},{"file_id":"1XvzVGJPTJifVh8OpZVB7ykLxyUqYwQ1j","timestamp":1617196833019},{"file_id":"1bv1_y32e3KEExFKKlPfC3rpw1JxmBr8H","timestamp":1617124341706},{"file_id":"1GMq8u7KyHB2AE7Teyls9gK1T01OduQSn","timestamp":1616697516760},{"file_id":"1Ui3kyHim-e0XLgDs2mkBxVlYg7TKYtcg","timestamp":1616615469755},{"file_id":"1YpHocGI4rApOxIBb1ZghCU5L-hFnv4CK","timestamp":1616608248670}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"YeuAheYyhdZw","executionInfo":{"status":"ok","timestamp":1757264424085,"user_tz":-330,"elapsed":9892,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}}},"source":["# import libraries\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader,TensorDataset\n","from sklearn.model_selection import train_test_split\n","\n","import time\n","\n","import matplotlib.pyplot as plt\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0HOkOefftqyg"},"source":["# Import and process the data"]},{"cell_type":"code","metadata":{"id":"MU7rvmWuhjud","executionInfo":{"status":"ok","timestamp":1757264428388,"user_tz":-330,"elapsed":4299,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}}},"source":["# import dataset (comes with colab!)\n","data = np.loadtxt(open('sample_data/mnist_train_small.csv','rb'),delimiter=',')\n","\n","# extract labels (number IDs) and remove from data\n","labels = data[:,0]\n","data   = data[:,1:]\n","\n","# normalize the data to a range of [0 1]\n","dataNorm = data / np.max(data)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y_tZ1ymVp0Sf","executionInfo":{"status":"ok","timestamp":1757264428767,"user_tz":-330,"elapsed":376,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}}},"source":["# Step 1: convert to tensor\n","dataT   = torch.tensor( dataNorm ).float()\n","labelsT = torch.tensor( labels ).long()\n","\n","# Step 2: use scikitlearn to split the data\n","train_data,test_data, train_labels,test_labels = train_test_split(dataT, labelsT, test_size=.1)\n","\n","# Step 3: convert into PyTorch Datasets\n","train_data = TensorDataset(train_data,train_labels)\n","test_data  = TensorDataset(test_data,test_labels)\n","\n","# Step 4: translate into dataloader objects\n","batchsize    = 32\n","train_loader = DataLoader(train_data,batch_size=batchsize,shuffle=True,drop_last=True)\n","test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OK8Opkhgp0bO"},"source":["# Create the DL model"]},{"cell_type":"code","metadata":{"id":"JK3OO3tAtZkA","executionInfo":{"status":"ok","timestamp":1757264428788,"user_tz":-330,"elapsed":8,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}}},"source":["# create a class for the model\n","def createTheMNISTNet():\n","\n","  class mnistNet(nn.Module):\n","    def __init__(self):\n","      super().__init__()\n","\n","      ### input layer\n","      self.input = nn.Linear(784,64)\n","\n","      ### hidden layer\n","      self.fc1 = nn.Linear(64,32)\n","      self.fc2 = nn.Linear(32,32)\n","\n","      ### output layer\n","      self.output = nn.Linear(32,10)\n","\n","    # forward pass\n","    def forward(self,x):\n","      x = F.relu( self.input(x) )\n","      x = F.relu( self.fc1(x) )\n","      x = F.relu( self.fc2(x) )\n","      return self.output(x)\n","\n","  # create the model instance\n","  net = mnistNet()\n","\n","  # loss function\n","  lossfun = nn.CrossEntropyLoss()\n","\n","  # optimizer (using SGD to slow down learning!)\n","  optimizer = torch.optim.SGD(net.parameters(),lr=.001)\n","\n","  return net,lossfun,optimizer"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iIWRXhKgiyVh"},"source":["# Brief inspection of requires_grad"]},{"cell_type":"code","metadata":{"id":"cU_oKoRFc9Ww","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757265121255,"user_tz":-330,"elapsed":49,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}},"outputId":"1eb0a40b-1480-4010-aa81-148ad1df20c6"},"source":["# inspect the \"learning toggle\" of a layer\n","N = createTheMNISTNet()\n","N[0].input.bias"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Parameter containing:\n","tensor([-0.0023,  0.0276, -0.0355,  0.0146, -0.0059,  0.0137, -0.0281,  0.0163,\n","        -0.0246,  0.0073,  0.0132, -0.0350, -0.0178,  0.0154,  0.0069, -0.0163,\n","         0.0127, -0.0266, -0.0028,  0.0330, -0.0015, -0.0151, -0.0150, -0.0097,\n","        -0.0305, -0.0325, -0.0259, -0.0083,  0.0066, -0.0148, -0.0161,  0.0276,\n","         0.0083, -0.0136, -0.0280,  0.0217, -0.0347, -0.0152, -0.0301,  0.0198,\n","        -0.0003,  0.0017, -0.0317, -0.0292, -0.0283,  0.0080,  0.0293, -0.0064,\n","         0.0161, -0.0295, -0.0033, -0.0044,  0.0354, -0.0002, -0.0323,  0.0201,\n","         0.0133,  0.0063, -0.0108, -0.0266, -0.0210, -0.0228, -0.0088,  0.0128],\n","       requires_grad=True)"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"43hUBq9-f6WY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757265122630,"user_tz":-330,"elapsed":7,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}},"outputId":"e27af65d-a84d-47fe-c750-04e86423c90f"},"source":["N = createTheMNISTNet()[0]\n","\n","# switch off all layers except input\n","for p in N.named_parameters():\n","  if 'input' not in p[0]:\n","    p[1].requires_grad = False\n","\n","\n","# check what we've done\n","for p in N.named_parameters():\n","  print('Requires_grad status in layer %s: %s' %(p[0],p[1].requires_grad))"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Requires_grad status in layer input.weight: True\n","Requires_grad status in layer input.bias: True\n","Requires_grad status in layer fc1.weight: False\n","Requires_grad status in layer fc1.bias: False\n","Requires_grad status in layer fc2.weight: False\n","Requires_grad status in layer fc2.bias: False\n","Requires_grad status in layer output.weight: False\n","Requires_grad status in layer output.bias: False\n"]}]},{"cell_type":"markdown","metadata":{"id":"dvfGQIRGp0ht"},"source":["# Create a function that trains the model"]},{"cell_type":"code","source":["for p in net.named_parameters():\n","  print(p[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M01sxLoWL_aE","executionInfo":{"status":"ok","timestamp":1757265532884,"user_tz":-330,"elapsed":8,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}},"outputId":"cc32fece-aa68-4f86-fcd3-37e92f6ae397"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["input.weight\n","input.bias\n","fc1.weight\n","fc1.bias\n","fc2.weight\n","fc2.bias\n","output.weight\n","output.bias\n"]}]},{"cell_type":"code","metadata":{"id":"IblJo1NCp0kl","executionInfo":{"status":"ok","timestamp":1757266249000,"user_tz":-330,"elapsed":13,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}}},"source":["def function2trainTheModel(net,lossfun,optimizer):\n","\n","  # number of epochs\n","  numepochs = 100\n","\n","  # initialize losses\n","  losses    = torch.zeros(numepochs)\n","  trainAcc  = []\n","  testAcc   = []\n","\n","\n","  # loop over epochs\n","  for epochi in range(numepochs):\n","\n","\n","\n","\n","    # NEW: switch off learning in all-but-output layers during first 1/2 of training\n","    # if epochi>(numepochs/2):\n","    #   for p in net.named_parameters():\n","    #     if 'output' not in p[0]:\n","    #       p[1].requires_grad = False\n","    # else:\n","    #   for p in net.named_parameters():\n","    #     p[1].requires_grad = True\n","\n","    # Turn off the weights and turn on the bias\n","    for p in net.named_parameters():\n","      if 'fc2' not in p[0]:\n","        p[1].requires_grad = False\n","      else:\n","        p[1].requires_grad = True\n","\n","\n","\n","    # loop over training data batches\n","    net.train()\n","    batchAcc  = []\n","    batchLoss = []\n","    for X,y in train_loader:\n","\n","      # forward pass and loss\n","      yHat = net(X)\n","      loss = lossfun(yHat,y)\n","\n","      # backprop\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","\n","      # loss from this batch\n","      batchLoss.append(loss.item())\n","\n","      # compute accuracy\n","      matches = torch.argmax(yHat,axis=1) == y     # booleans (false/true)\n","      matchesNumeric = matches.float()             # convert to numbers (0/1)\n","      accuracyPct = 100*torch.mean(matchesNumeric) # average and x100\n","      batchAcc.append( accuracyPct )               # add to list of accuracies\n","    # end of batch loop...\n","\n","    # now that we've trained through the batches, get their average training accuracy\n","    trainAcc.append( np.mean(batchAcc) )\n","\n","    # and get average losses across the batches\n","    losses[epochi] = np.mean(batchLoss)\n","\n","    # test accuracy\n","    net.eval()\n","    X,y = next(iter(test_loader)) # extract X,y from test dataloader\n","    with torch.no_grad(): # deactivates autograd\n","      yHat = net(X)\n","\n","    # compare the following really long line of code to the training accuracy lines\n","    testAcc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) )\n","  # end epochs\n","\n","  # function output\n","  return trainAcc,testAcc,losses,net"],"execution_count":43,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-2rpKarsEegk"},"source":["# Let's see it in action!"]},{"cell_type":"code","metadata":{"id":"gHzKOZjnp0qn"},"source":["# create the network\n","net,lossfun,optimizer = createTheMNISTNet()\n","\n","# train the model\n","trainAcc,testAcc,losses,net = function2trainTheModel(net,lossfun,optimizer)\n","\n","plt.plot(trainAcc,label='Train')\n","plt.plot(testAcc,label='Test')\n","# plt.plot([len(trainAcc)/2, len(trainAcc)/2],[10,80],'k--',label='Learning switched on')\n","plt.title(f'Final train accuracy: {trainAcc[-1]:.2f}%\\n Final test accuracy: {testAcc[-1]:0.2f}%')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy (%)')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kkuO4rvVEsoV"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7KP-981UsbjS"},"source":["# Additional explorations"]},{"cell_type":"code","metadata":{"id":"JdnIdmBjsd2U"},"source":["# 1) Switch off all the weights, but leave all the biases switched on. Can the model still learn (at least, better than\n","#    chance level)? Then do the opposite: let the weights learn but turn off learnign in the biases. How does the model\n","#    perform now, and what does this tell you about weights vs. biases?\n","#\n","# 2) Freeze only one layer, e.g., layer fc1 (freeze both the weights and biases). Store the accuracy output as a separate\n","#    variable, so you run the network again without freezing anything. Then plot the accuracies (with and without\n","#    freezing) on the same graph. How important is fc1 based on this plot?\n","#"],"execution_count":null,"outputs":[]}]}