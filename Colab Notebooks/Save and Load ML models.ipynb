{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOW5Z33RkOirf8oGSiA9ILX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Y7vNVun3NXj","executionInfo":{"status":"ok","timestamp":1763232809100,"user_tz":-330,"elapsed":27325,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}},"outputId":"aff3a67f-c144-447e-9881-524b71886a4d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MCcPEWp_3ExD","executionInfo":{"status":"ok","timestamp":1763232987592,"user_tz":-330,"elapsed":54,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}},"outputId":"da60f6f0-6ba0-4eab-a5bc-a66a5cf3cd6a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing /content/drive/MyDrive/GitHub/Python-2/Helper Functions/save_load_models_utils.py\n"]}],"source":["%%writefile \"/content/drive/MyDrive/GitHub/Python-2/Helper Functions/save_load_models_utils.py\"\n","# save_load_models_utils.py\n","\n","from __future__ import annotations\n","\n","import importlib\n","from pathlib import Path\n","from typing import Any, Dict, List, Optional, Tuple, Callable\n","\n","import torch\n","from torch import nn\n","from torch.optim import Optimizer\n","from torch.optim.lr_scheduler import _LRScheduler\n","from torch.cuda.amp import GradScaler\n","\n","\n","def _to_path(path: str | Path) -> Path:\n","    return path if isinstance(path, Path) else Path(path)\n","\n","\n","# ============================================================\n","# 1. SAVE CHECKPOINT\n","# ============================================================\n","\n","def save_checkpoint(\n","    save_path: str | Path,\n","    model: nn.Module,\n","    *,\n","    model_kwargs: Optional[Dict[str, Any]] = None,\n","    class_names: Optional[List[str]] = None,\n","    heads_class_names: Optional[Dict[str, List[str]]] = None,\n","    img_size: Optional[int] = None,\n","    optimizer: Optional[Optimizer] = None,\n","    scheduler: Optional[_LRScheduler] = None,\n","    scaler: Optional[GradScaler] = None,\n","    epoch: Optional[int] = None,\n","    global_step: Optional[int] = None,\n","    best_metric: Optional[float] = None,\n","    extra_metadata: Optional[Dict[str, Any]] = None,\n",") -> None:\n","    \"\"\"\n","    Save a rich checkpoint containing:\n","      - model state_dict\n","      - architecture info (module, class name, kwargs)\n","      - class names (single head or multiple heads)\n","      - training state: optimizer, scheduler, scaler, epoch, global_step, best_metric\n","      - extra_metadata: anything else you want\n","\n","    Args:\n","        save_path: where to save (.pth)\n","        model: trained model (nn.Module)\n","        model_kwargs: kwargs needed to reconstruct the model (num_classes, image_size, etc.)\n","        class_names: list of class names for single-head models\n","        heads_class_names: dict of {head_name: [class names]} for multi-head models\n","        img_size: input image size if relevant (e.g. 224, 384)\n","        optimizer: optional optimizer whose state will be saved\n","        scheduler: optional LR scheduler whose state will be saved\n","        scaler: optional GradScaler (for AMP) whose state will be saved\n","        epoch: current epoch (for resume)\n","        global_step: global training step (for resume)\n","        best_metric: best validation metric so far (for resume)\n","        extra_metadata: any extra info you want (dict)\n","    \"\"\"\n","    save_path = _to_path(save_path)\n","    save_path.parent.mkdir(parents=True, exist_ok=True)\n","\n","    # Architecture info\n","    arch_info = {\n","        \"module\": model.__class__.__module__,   # e.g. \"torchvision.models.vision_transformer\"\n","        \"class_name\": model.__class__.__name__, # e.g. \"VisionTransformer\"\n","        \"kwargs\": model_kwargs or {},           # user-provided kwargs\n","    }\n","\n","    # Class info\n","    class_info: Dict[str, Any] = {}\n","    if class_names is not None:\n","        class_info[\"class_names\"] = class_names\n","        class_info[\"num_classes\"] = len(class_names)\n","    if heads_class_names is not None:\n","        class_info[\"heads_class_names\"] = heads_class_names\n","        # Optional: derive num_classes per head\n","        class_info[\"heads_num_classes\"] = {\n","            head: len(names) for head, names in heads_class_names.items()\n","        }\n","\n","    # Generic metadata\n","    metadata: Dict[str, Any] = {\n","        \"arch\": arch_info,\n","        \"class_info\": class_info,\n","        \"img_size\": img_size,\n","    }\n","    if extra_metadata:\n","        metadata[\"extra\"] = extra_metadata\n","\n","    # Training state\n","    train_state: Dict[str, Any] = {\n","        \"epoch\": epoch,\n","        \"global_step\": global_step,\n","        \"best_metric\": best_metric,\n","    }\n","\n","    if optimizer is not None:\n","        train_state[\"optimizer\"] = optimizer.state_dict()\n","    if scheduler is not None:\n","        train_state[\"scheduler\"] = scheduler.state_dict()\n","    if scaler is not None:\n","        train_state[\"scaler\"] = scaler.state_dict()\n","\n","    checkpoint = {\n","        \"state_dict\": model.state_dict(),\n","        \"metadata\": metadata,\n","        \"train_state\": train_state,\n","        \"format_version\": 1,\n","    }\n","\n","    torch.save(checkpoint, save_path)\n","    print(f\"✅ Checkpoint saved to: {save_path.resolve()}\")\n","\n","\n","# ============================================================\n","# 2. LOAD CHECKPOINT\n","# ============================================================\n","\n","def _build_model_from_arch_info(\n","    arch_info: Dict[str, Any],\n","    device: str | torch.device,\n","    override_model_builder: Optional[Callable[..., nn.Module]] = None,\n",") -> nn.Module:\n","    \"\"\"\n","    Rebuild a model from arch_info (module, class_name, kwargs).\n","\n","    If override_model_builder is provided, it's used as:\n","        model = override_model_builder(arch_info)\n","\n","    Else:\n","        - dynamically imports module and gets class by name\n","        - instantiates with arch_info[\"kwargs\"]\n","    \"\"\"\n","    if override_model_builder is not None:\n","        model = override_model_builder(arch_info)\n","        return model.to(device)\n","\n","    module_name = arch_info[\"module\"]\n","    class_name = arch_info[\"class_name\"]\n","    kwargs = arch_info.get(\"kwargs\", {})\n","\n","    module = importlib.import_module(module_name)\n","    model_cls = getattr(module, class_name)\n","    model = model_cls(**kwargs)\n","    return model.to(device)\n","\n","\n","def load_checkpoint(\n","    checkpoint_path: str | Path,\n","    device: str | torch.device = \"cpu\",\n","    *,\n","    override_model_builder: Optional[Callable[[Dict[str, Any]], nn.Module]] = None,\n","    strict: bool = True,\n","    optimizer: Optional[Optimizer] = None,\n","    scheduler: Optional[_LRScheduler] = None,\n","    scaler: Optional[GradScaler] = None,\n",") -> Tuple[nn.Module, Dict[str, Any], Dict[str, Any]]:\n","    \"\"\"\n","    Load a rich checkpoint and reconstruct the model.\n","\n","    Args:\n","        checkpoint_path: path to .pth checkpoint\n","        device: device to map tensors to (\"cpu\", \"cuda\", \"mps\", or torch.device)\n","        override_model_builder:\n","            Optional callable taking arch_info and returning a model instance.\n","            Use this if:\n","              - you want to map a generic arch_info to a specific torchvision function\n","              - you changed your code but still want to load old checkpoints\n","        strict: passed to model.load_state_dict(strict=strict)\n","        optimizer: if provided, its state will be loaded from the checkpoint (if available)\n","        scheduler: if provided, its state will be loaded\n","        scaler: if provided, its state will be loaded\n","\n","    Returns:\n","        model: nn.Module with loaded weights\n","        metadata: dict with \"arch\", \"class_info\", \"img_size\", \"extra\"\n","        train_state: dict with \"epoch\", \"global_step\", \"best_metric\", and possibly others\n","    \"\"\"\n","    checkpoint_path = _to_path(checkpoint_path)\n","    checkpoint = torch.load(checkpoint_path, map_location=device)\n","\n","    state_dict = checkpoint[\"state_dict\"]\n","    metadata = checkpoint.get(\"metadata\", {})\n","    train_state = checkpoint.get(\"train_state\", {})\n","\n","    arch_info = metadata.get(\"arch\")\n","    if arch_info is None:\n","        raise ValueError(\"Checkpoint missing 'arch' info; cannot auto-rebuild model.\")\n","\n","    # Build model from arch info\n","    model = _build_model_from_arch_info(\n","        arch_info=arch_info,\n","        device=device,\n","        override_model_builder=override_model_builder,\n","    )\n","\n","    # Load weights\n","    missing, unexpected = model.load_state_dict(state_dict, strict=strict)\n","    print(f\"✅ Model loaded from: {checkpoint_path.resolve()}\")\n","    print(f\"   Missing keys   : {missing}\")\n","    print(f\"   Unexpected keys: {unexpected}\")\n","\n","    # Optionally restore optimizer/scheduler/scaler\n","    if optimizer is not None and \"optimizer\" in train_state:\n","        optimizer.load_state_dict(train_state[\"optimizer\"])\n","        print(\"   ✅ Optimizer state restored.\")\n","\n","    if scheduler is not None and \"scheduler\" in train_state:\n","        scheduler.load_state_dict(train_state[\"scheduler\"])\n","        print(\"   ✅ Scheduler state restored.\")\n","\n","    if scaler is not None and \"scaler\" in train_state:\n","        scaler.load_state_dict(train_state[\"scaler\"])\n","        print(\"   ✅ GradScaler state restored.\")\n","\n","    model.eval()\n","    return model, metadata, train_state\n"]},{"cell_type":"code","source":[],"metadata":{"id":"gwrv8CUf3HyC"},"execution_count":null,"outputs":[]}]}