{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyPq5sVDUy+cN2YQqa/jZCwX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":51,"metadata":{"id":"IuaeSpVsG2Lq","executionInfo":{"status":"ok","timestamp":1766331573755,"user_tz":-330,"elapsed":6,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from time import process_time"]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"wE-5QILmHS-g","executionInfo":{"status":"ok","timestamp":1766323715056,"user_tz":-330,"elapsed":3,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}},"outputId":"ba98890e-1f28-480b-ccfe-05f73edade0c"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cuda'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["# Hyperparameters"],"metadata":{"id":"gZjrpzPwIuhv"}},{"cell_type":"code","metadata":{"id":"f8d1bbd9","executionInfo":{"status":"ok","timestamp":1766323715058,"user_tz":-330,"elapsed":1,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}}},"source":["n_vocab = 50257 # GPT-2 vocabulary size\n","embed_dim = 768 # GPT-2 embedding domension size\n","seq_len = 1024 # GPT-2 sequence length/ context window size\n","n_heads = 12 # GPT-2 number of heads\n","n_layers = 12 # GPT-2 number of layers/ number of transfomer blocks\n","batch_size = 8"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# Create a Multihead attention class"],"metadata":{"id":"iGDj7OYTdhAl"}},{"cell_type":"code","source":["class MultiHeadAttention(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.n_heads = n_heads\n","    self.head_dim = embed_dim // n_heads\n","\n","    self.QKV = nn.Linear(embed_dim, 3 * embed_dim, bias=True)\n","\n","    # Linear mixing after attention\n","    self.W0 = nn.Linear(embed_dim, embed_dim, bias=True)\n","\n","  def forward(self, x, track_sizes=False):\n","\n","    B, T, E = x.shape # Batch, seq_length, embedding dimension\n","\n","    qkv = self.QKV(x)\n","    q, k, v = torch.split(qkv, embed_dim, dim=-1) # split into separate matrices\n","    if track_sizes: print(f\"1){' QKV shape:':>28} {qkv.shape}\")\n","    if track_sizes: print(f\"1a){' q shape:':>28} {q.shape}\")\n","\n","    # Reshape the q, k, v matrices into [Batch, n_heads, seq_length (T), head_dim] --> SDPA needs the tensor of shape [B, n_heads, T, head_dim]\n","    q = q.view(B, T, self.n_heads, self.head_dim).transpose(1, 2)\n","    k = k.view(B, T, self.n_heads, self.head_dim).transpose(1, 2)\n","    v = v.view(B, T, self.n_heads, self.head_dim).transpose(1, 2)\n","    if track_sizes: print(f\"2){' Q shape after reshape:':>28} {q.shape}\")\n","\n","    # SDPA and transpose the matrix again\n","    out = F.scaled_dot_product_attention(q, k, v, is_causal=True).transpose(1,2).reshape(B, T, E)\n","    if track_sizes: print(f\"3){' Attention output shape:':>28} {out.shape}\")\n","\n","    # Pass it through the Linear mixing matrix\n","    out = self.W0(out)\n","    if track_sizes: print(f\"4){' Final output shape:':>28} {out.shape}\")\n","\n","    return out"],"metadata":{"id":"UOoV6P16IFSs","executionInfo":{"status":"ok","timestamp":1766324521164,"user_tz":-330,"elapsed":44,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["mha = MultiHeadAttention()\n","out = mha(torch.randn(batch_size, seq_len, embed_dim),track_sizes=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jiCzrIJcinLa","executionInfo":{"status":"ok","timestamp":1766324522742,"user_tz":-330,"elapsed":280,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}},"outputId":"dbd28f9e-2cb7-485a-bc17-839827a13066"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["1)                  QKV shape: torch.Size([8, 1024, 2304])\n","1a)                    q shape: torch.Size([8, 1024, 768])\n","2)      Q shape after reshape: torch.Size([8, 12, 1024, 64])\n","3)     Attention output shape: torch.Size([8, 1024, 768])\n","4)         Final output shape: torch.Size([8, 1024, 768])\n"]}]},{"cell_type":"markdown","source":["# Create the Tranformer Block"],"metadata":{"id":"VsbNqEG2GVGS"}},{"cell_type":"code","source":["class TransformerBlock(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.mha = MultiHeadAttention()\n","    self.layernorm1 = nn.LayerNorm(embed_dim)\n","    self.layernorm2 = nn.LayerNorm(embed_dim)\n","    self.ff = nn.Sequential(\n","        nn.Linear(embed_dim, 4 * embed_dim),\n","        nn.GELU(),\n","        nn.Linear(4 * embed_dim, embed_dim)\n","    )\n","\n","  def forward(self, x):\n","\n","    # Attention\n","    out_attn = x + self.mha(self.layernorm1(x)) # pre-attention normalization + attention\n","\n","    # MLP layer\n","    out = out_attn + self.ff(self.layernorm2(out_attn)) # post-attention normalization + MLP\n","\n","    return out\n"],"metadata":{"id":"iVkdXDQYkiYy","executionInfo":{"status":"ok","timestamp":1766330987805,"user_tz":-330,"elapsed":40,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["transform = TransformerBlock()\n","out = transform(torch.randn(batch_size, seq_len, embed_dim))\n","\n","out.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ocGygNqhICeQ","executionInfo":{"status":"ok","timestamp":1766330990897,"user_tz":-330,"elapsed":355,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}},"outputId":"71bf2c3b-f59f-4043-d3e3-52de9ec59784"},"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([8, 1024, 768])"]},"metadata":{},"execution_count":36}]},{"cell_type":"markdown","source":["# Create the entire model"],"metadata":{"id":"Ms_R16EtJk0n"}},{"cell_type":"code","source":["class LLModel(nn.Module):\n","  def __init__(self, device):\n","    super().__init__()\n","\n","    # token + position embeddings\n","    self.wte = nn.Embedding(n_vocab, embed_dim) # token embedding\n","    self.wpe = nn.Embedding(seq_len, embed_dim) # position embedding\n","\n","    # transformer blocks\n","    self.blocks = nn.Sequential(*[TransformerBlock() for _ in range(n_layers)])\n","\n","    # final layernorm\n","    self.layernorm = nn.LayerNorm(embed_dim)\n","\n","    # final head\n","    self.head = nn.Linear(embed_dim, n_vocab)\n","    self.head.weight = nn.Parameter(self.wte.weight) # share weights\n","\n","    self.device = device\n","\n","  def forward(self, x):\n","    token_emb = self.wte(x) # [B,T,E]\n","    position_embed = self.wpe(torch.arange(x.shape[-1], device=self.device)) #[T,E]\n","    out = token_emb + position_embed #[T,E]\n","\n","    # Pass through transformer blocks\n","    out = self.blocks(out)\n","\n","    # Pass through final layernorm\n","    out = self.layernorm(out)\n","\n","    # Pass through final head/ MLP\n","    out = self.head(out) # [B,T,n_vocab]\n","    return out\n","\n","  def generate(self, tokx, temperature=1., max_new_tokens=50):\n","    for _ in range(max_new_tokens):\n","\n","      # forward pass\n","      logits = self(tokx[:, -seq_len:]) # [B,n_vocab]\n","\n","      # Apply temeprature and softmax\n","      probs = F.softmax(logits / temperature, dim=-1) # [B, n_vocab]\n","\n","      # Next sample token\n","      tokx_next = torch.multinomial(probs, num_samples=1)\n","\n","      # Add to the sequence\n","      tokx = torch.cat((tokx, tokx_next), dim=1)\n","    return tokx"],"metadata":{"id":"ojRTGRuRIh3W","executionInfo":{"status":"ok","timestamp":1766331391741,"user_tz":-330,"elapsed":4,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["model = LLModel(device)\n","model\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OYAQOO6LOihr","executionInfo":{"status":"ok","timestamp":1766331412197,"user_tz":-330,"elapsed":1147,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}},"outputId":"1e30a753-267b-4e91-e50c-83e167c889dc"},"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LLModel(\n","  (wte): Embedding(50257, 768)\n","  (wpe): Embedding(1024, 768)\n","  (blocks): Sequential(\n","    (0): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (QKV): Linear(in_features=768, out_features=2304, bias=True)\n","        (W0): Linear(in_features=768, out_features=768, bias=True)\n","      )\n","      (layernorm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (layernorm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (ff): Sequential(\n","        (0): Linear(in_features=768, out_features=3072, bias=True)\n","        (1): GELU(approximate='none')\n","        (2): Linear(in_features=3072, out_features=768, bias=True)\n","      )\n","    )\n","    (1): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (QKV): Linear(in_features=768, out_features=2304, bias=True)\n","        (W0): Linear(in_features=768, out_features=768, bias=True)\n","      )\n","      (layernorm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (layernorm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (ff): Sequential(\n","        (0): Linear(in_features=768, out_features=3072, bias=True)\n","        (1): GELU(approximate='none')\n","        (2): Linear(in_features=3072, out_features=768, bias=True)\n","      )\n","    )\n","    (2): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (QKV): Linear(in_features=768, out_features=2304, bias=True)\n","        (W0): Linear(in_features=768, out_features=768, bias=True)\n","      )\n","      (layernorm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (layernorm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (ff): Sequential(\n","        (0): Linear(in_features=768, out_features=3072, bias=True)\n","        (1): GELU(approximate='none')\n","        (2): Linear(in_features=3072, out_features=768, bias=True)\n","      )\n","    )\n","    (3): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (QKV): Linear(in_features=768, out_features=2304, bias=True)\n","        (W0): Linear(in_features=768, out_features=768, bias=True)\n","      )\n","      (layernorm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (layernorm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (ff): Sequential(\n","        (0): Linear(in_features=768, out_features=3072, bias=True)\n","        (1): GELU(approximate='none')\n","        (2): Linear(in_features=3072, out_features=768, bias=True)\n","      )\n","    )\n","    (4): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (QKV): Linear(in_features=768, out_features=2304, bias=True)\n","        (W0): Linear(in_features=768, out_features=768, bias=True)\n","      )\n","      (layernorm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (layernorm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (ff): Sequential(\n","        (0): Linear(in_features=768, out_features=3072, bias=True)\n","        (1): GELU(approximate='none')\n","        (2): Linear(in_features=3072, out_features=768, bias=True)\n","      )\n","    )\n","    (5): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (QKV): Linear(in_features=768, out_features=2304, bias=True)\n","        (W0): Linear(in_features=768, out_features=768, bias=True)\n","      )\n","      (layernorm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (layernorm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (ff): Sequential(\n","        (0): Linear(in_features=768, out_features=3072, bias=True)\n","        (1): GELU(approximate='none')\n","        (2): Linear(in_features=3072, out_features=768, bias=True)\n","      )\n","    )\n","    (6): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (QKV): Linear(in_features=768, out_features=2304, bias=True)\n","        (W0): Linear(in_features=768, out_features=768, bias=True)\n","      )\n","      (layernorm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (layernorm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (ff): Sequential(\n","        (0): Linear(in_features=768, out_features=3072, bias=True)\n","        (1): GELU(approximate='none')\n","        (2): Linear(in_features=3072, out_features=768, bias=True)\n","      )\n","    )\n","    (7): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (QKV): Linear(in_features=768, out_features=2304, bias=True)\n","        (W0): Linear(in_features=768, out_features=768, bias=True)\n","      )\n","      (layernorm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (layernorm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (ff): Sequential(\n","        (0): Linear(in_features=768, out_features=3072, bias=True)\n","        (1): GELU(approximate='none')\n","        (2): Linear(in_features=3072, out_features=768, bias=True)\n","      )\n","    )\n","    (8): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (QKV): Linear(in_features=768, out_features=2304, bias=True)\n","        (W0): Linear(in_features=768, out_features=768, bias=True)\n","      )\n","      (layernorm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (layernorm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (ff): Sequential(\n","        (0): Linear(in_features=768, out_features=3072, bias=True)\n","        (1): GELU(approximate='none')\n","        (2): Linear(in_features=3072, out_features=768, bias=True)\n","      )\n","    )\n","    (9): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (QKV): Linear(in_features=768, out_features=2304, bias=True)\n","        (W0): Linear(in_features=768, out_features=768, bias=True)\n","      )\n","      (layernorm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (layernorm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (ff): Sequential(\n","        (0): Linear(in_features=768, out_features=3072, bias=True)\n","        (1): GELU(approximate='none')\n","        (2): Linear(in_features=3072, out_features=768, bias=True)\n","      )\n","    )\n","    (10): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (QKV): Linear(in_features=768, out_features=2304, bias=True)\n","        (W0): Linear(in_features=768, out_features=768, bias=True)\n","      )\n","      (layernorm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (layernorm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (ff): Sequential(\n","        (0): Linear(in_features=768, out_features=3072, bias=True)\n","        (1): GELU(approximate='none')\n","        (2): Linear(in_features=3072, out_features=768, bias=True)\n","      )\n","    )\n","    (11): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (QKV): Linear(in_features=768, out_features=2304, bias=True)\n","        (W0): Linear(in_features=768, out_features=768, bias=True)\n","      )\n","      (layernorm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (layernorm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (ff): Sequential(\n","        (0): Linear(in_features=768, out_features=3072, bias=True)\n","        (1): GELU(approximate='none')\n","        (2): Linear(in_features=3072, out_features=768, bias=True)\n","      )\n","    )\n","  )\n","  (layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  (head): Linear(in_features=768, out_features=50257, bias=True)\n",")"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["data = torch.randint(0, n_vocab, (batch_size, seq_len)).to(device)\n","data.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tKtAFvRbantG","executionInfo":{"status":"ok","timestamp":1766331416597,"user_tz":-330,"elapsed":3,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}},"outputId":"d247796c-acff-430c-f940-5052c90c6863"},"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([8, 1024])"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["model.to(device)\n","out = model(data)\n","out.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hySAYxY3boIA","executionInfo":{"status":"ok","timestamp":1766331417720,"user_tz":-330,"elapsed":194,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}},"outputId":"64640a77-1614-43d9-b3a0-7884d0962125"},"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([8, 1024, 50257])"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["!pip install torchinfo\n","from torchinfo import summary"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3QOjf9G3btp2","executionInfo":{"status":"ok","timestamp":1766331429339,"user_tz":-330,"elapsed":4292,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}},"outputId":"9b16f705-f3da-42c5-fc84-afe6c1dee8e1"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchinfo in /usr/local/lib/python3.12/dist-packages (1.8.0)\n"]}]},{"cell_type":"code","source":["summary(model, input_size=(batch_size, seq_len), dtypes=[torch.long], col_names=['input_size','output_size','num_params','trainable'], row_settings=['var_names'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vbRT5OVpc7A4","executionInfo":{"status":"ok","timestamp":1766331431074,"user_tz":-330,"elapsed":9,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}},"outputId":"9a7fc615-bf0f-43c4-b0ae-067d5fb5cbce"},"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/plain":["============================================================================================================================================\n","Layer (type (var_name))                  Input Shape               Output Shape              Param #                   Trainable\n","============================================================================================================================================\n","LLModel (LLModel)                        [8, 1024]                 [8, 1024, 50257]          --                        True\n","├─Embedding (wte)                        [8, 1024]                 [8, 1024, 768]            38,597,376                True\n","├─Embedding (wpe)                        [1024]                    [1024, 768]               786,432                   True\n","├─Sequential (blocks)                    [8, 1024, 768]            [8, 1024, 768]            --                        True\n","│    └─TransformerBlock (0)              [8, 1024, 768]            [8, 1024, 768]            --                        True\n","│    │    └─LayerNorm (layernorm1)       [8, 1024, 768]            [8, 1024, 768]            1,536                     True\n","│    │    └─MultiHeadAttention (mha)     [8, 1024, 768]            [8, 1024, 768]            2,362,368                 True\n","│    │    └─LayerNorm (layernorm2)       [8, 1024, 768]            [8, 1024, 768]            1,536                     True\n","│    │    └─Sequential (ff)              [8, 1024, 768]            [8, 1024, 768]            4,722,432                 True\n","│    └─TransformerBlock (1)              [8, 1024, 768]            [8, 1024, 768]            --                        True\n","│    │    └─LayerNorm (layernorm1)       [8, 1024, 768]            [8, 1024, 768]            1,536                     True\n","│    │    └─MultiHeadAttention (mha)     [8, 1024, 768]            [8, 1024, 768]            2,362,368                 True\n","│    │    └─LayerNorm (layernorm2)       [8, 1024, 768]            [8, 1024, 768]            1,536                     True\n","│    │    └─Sequential (ff)              [8, 1024, 768]            [8, 1024, 768]            4,722,432                 True\n","│    └─TransformerBlock (2)              [8, 1024, 768]            [8, 1024, 768]            --                        True\n","│    │    └─LayerNorm (layernorm1)       [8, 1024, 768]            [8, 1024, 768]            1,536                     True\n","│    │    └─MultiHeadAttention (mha)     [8, 1024, 768]            [8, 1024, 768]            2,362,368                 True\n","│    │    └─LayerNorm (layernorm2)       [8, 1024, 768]            [8, 1024, 768]            1,536                     True\n","│    │    └─Sequential (ff)              [8, 1024, 768]            [8, 1024, 768]            4,722,432                 True\n","│    └─TransformerBlock (3)              [8, 1024, 768]            [8, 1024, 768]            --                        True\n","│    │    └─LayerNorm (layernorm1)       [8, 1024, 768]            [8, 1024, 768]            1,536                     True\n","│    │    └─MultiHeadAttention (mha)     [8, 1024, 768]            [8, 1024, 768]            2,362,368                 True\n","│    │    └─LayerNorm (layernorm2)       [8, 1024, 768]            [8, 1024, 768]            1,536                     True\n","│    │    └─Sequential (ff)              [8, 1024, 768]            [8, 1024, 768]            4,722,432                 True\n","│    └─TransformerBlock (4)              [8, 1024, 768]            [8, 1024, 768]            --                        True\n","│    │    └─LayerNorm (layernorm1)       [8, 1024, 768]            [8, 1024, 768]            1,536                     True\n","│    │    └─MultiHeadAttention (mha)     [8, 1024, 768]            [8, 1024, 768]            2,362,368                 True\n","│    │    └─LayerNorm (layernorm2)       [8, 1024, 768]            [8, 1024, 768]            1,536                     True\n","│    │    └─Sequential (ff)              [8, 1024, 768]            [8, 1024, 768]            4,722,432                 True\n","│    └─TransformerBlock (5)              [8, 1024, 768]            [8, 1024, 768]            --                        True\n","│    │    └─LayerNorm (layernorm1)       [8, 1024, 768]            [8, 1024, 768]            1,536                     True\n","│    │    └─MultiHeadAttention (mha)     [8, 1024, 768]            [8, 1024, 768]            2,362,368                 True\n","│    │    └─LayerNorm (layernorm2)       [8, 1024, 768]            [8, 1024, 768]            1,536                     True\n","│    │    └─Sequential (ff)              [8, 1024, 768]            [8, 1024, 768]            4,722,432                 True\n","│    └─TransformerBlock (6)              [8, 1024, 768]            [8, 1024, 768]            --                        True\n","│    │    └─LayerNorm (layernorm1)       [8, 1024, 768]            [8, 1024, 768]            1,536                     True\n","│    │    └─MultiHeadAttention (mha)     [8, 1024, 768]            [8, 1024, 768]            2,362,368                 True\n","│    │    └─LayerNorm (layernorm2)       [8, 1024, 768]            [8, 1024, 768]            1,536                     True\n","│    │    └─Sequential (ff)              [8, 1024, 768]            [8, 1024, 768]            4,722,432                 True\n","│    └─TransformerBlock (7)              [8, 1024, 768]            [8, 1024, 768]            --                        True\n","│    │    └─LayerNorm (layernorm1)       [8, 1024, 768]            [8, 1024, 768]            1,536                     True\n","│    │    └─MultiHeadAttention (mha)     [8, 1024, 768]            [8, 1024, 768]            2,362,368                 True\n","│    │    └─LayerNorm (layernorm2)       [8, 1024, 768]            [8, 1024, 768]            1,536                     True\n","│    │    └─Sequential (ff)              [8, 1024, 768]            [8, 1024, 768]            4,722,432                 True\n","│    └─TransformerBlock (8)              [8, 1024, 768]            [8, 1024, 768]            --                        True\n","│    │    └─LayerNorm (layernorm1)       [8, 1024, 768]            [8, 1024, 768]            1,536                     True\n","│    │    └─MultiHeadAttention (mha)     [8, 1024, 768]            [8, 1024, 768]            2,362,368                 True\n","│    │    └─LayerNorm (layernorm2)       [8, 1024, 768]            [8, 1024, 768]            1,536                     True\n","│    │    └─Sequential (ff)              [8, 1024, 768]            [8, 1024, 768]            4,722,432                 True\n","│    └─TransformerBlock (9)              [8, 1024, 768]            [8, 1024, 768]            --                        True\n","│    │    └─LayerNorm (layernorm1)       [8, 1024, 768]            [8, 1024, 768]            1,536                     True\n","│    │    └─MultiHeadAttention (mha)     [8, 1024, 768]            [8, 1024, 768]            2,362,368                 True\n","│    │    └─LayerNorm (layernorm2)       [8, 1024, 768]            [8, 1024, 768]            1,536                     True\n","│    │    └─Sequential (ff)              [8, 1024, 768]            [8, 1024, 768]            4,722,432                 True\n","│    └─TransformerBlock (10)             [8, 1024, 768]            [8, 1024, 768]            --                        True\n","│    │    └─LayerNorm (layernorm1)       [8, 1024, 768]            [8, 1024, 768]            1,536                     True\n","│    │    └─MultiHeadAttention (mha)     [8, 1024, 768]            [8, 1024, 768]            2,362,368                 True\n","│    │    └─LayerNorm (layernorm2)       [8, 1024, 768]            [8, 1024, 768]            1,536                     True\n","│    │    └─Sequential (ff)              [8, 1024, 768]            [8, 1024, 768]            4,722,432                 True\n","│    └─TransformerBlock (11)             [8, 1024, 768]            [8, 1024, 768]            --                        True\n","│    │    └─LayerNorm (layernorm1)       [8, 1024, 768]            [8, 1024, 768]            1,536                     True\n","│    │    └─MultiHeadAttention (mha)     [8, 1024, 768]            [8, 1024, 768]            2,362,368                 True\n","│    │    └─LayerNorm (layernorm2)       [8, 1024, 768]            [8, 1024, 768]            1,536                     True\n","│    │    └─Sequential (ff)              [8, 1024, 768]            [8, 1024, 768]            4,722,432                 True\n","├─LayerNorm (layernorm)                  [8, 1024, 768]            [8, 1024, 768]            1,536                     True\n","├─Linear (head)                          [8, 1024, 768]            [8, 1024, 50257]          38,647,633                True\n","============================================================================================================================================\n","Total params: 163,087,441\n","Trainable params: 163,087,441\n","Non-trainable params: 0\n","Total mult-adds (Units.GIGABYTES): 2.10\n","============================================================================================================================================\n","Input size (MB): 0.07\n","Forward/backward pass size (MB): 10044.38\n","Params size (MB): 652.35\n","Estimated Total Size (MB): 10696.79\n","============================================================================================================================================"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["# Instantiate once on CPU and then on GPU and run forward pass 5 times on a sample data\n","\n","num_runs = 5\n","data = torch.randint(0, n_vocab, (batch_size, seq_len))\n","\n","# Run on CPU\n","start_time = process_time()\n","for _ in range(num_runs):\n","  model = LLModel('cpu')\n","  out = model(data)\n","print(f'Elapsed time CPU: {process_time()-start_time:,.3f} sec')\n","\n","# Run on GPU\n","start_time = process_time()\n","for _ in range(num_runs):\n","  model = LLModel(device).to(device)\n","  data = data.to(device)\n","  out = model(data)\n","print(f'Elapsed time GPU: {process_time()-start_time:,.3f} sec')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Me5JknsVdCoV","executionInfo":{"status":"ok","timestamp":1766332321181,"user_tz":-330,"elapsed":32025,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}},"outputId":"e0782de5-e39a-4f3d-8f25-750547ac365b"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["Elapsed time CPU: 126.069 sec\n","Elapsed time GPU: 5.911 sec\n"]}]},{"cell_type":"code","source":["def loss_optim(model, data, device):\n","  # Define loss function and optimizer\n","  loss_func = nn.NLLLoss().to(device)\n","  optimizer = torch.optim.AdamW(model.parameters(),lr=0.001)\n","  data = data.to(device)\n","  model = LLModel(device=device).to(device=device)\n","\n","  # Forward pass\n","  out = model(data)\n","\n","  # Calculate loss\n","  loss = loss_func(out.view(-1, n_vocab), data.view(-1))\n","\n","  # back-propagation to compute the gradients\n","  model.zero_grad() # Initialize the gradients\n","  loss.backward() # back-propagation of loss function to compute the gradients over the loss function\n","  optimizer.step() # Re-compute the trainable weight parameters\n","\n","  return loss"],"metadata":{"id":"IlU2ckDPluOK","executionInfo":{"status":"ok","timestamp":1766334507213,"user_tz":-330,"elapsed":2,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}}},"execution_count":68,"outputs":[]},{"cell_type":"code","source":["# model = LLModel('cpu')\n","data = torch.randint(0, n_vocab, (batch_size, seq_len))\n","\n","%timeit loss_optim(model, data,'cpu')\n","%timeit loss_optim(model, data, device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xEtIHlBwpxpg","executionInfo":{"status":"ok","timestamp":1766335100606,"user_tz":-330,"elapsed":113973,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}},"outputId":"dfe457f5-bd26-4298-9a20-db251d984f4e"},"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["12.8 s ± 96.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n","1.49 s ± 14.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"4712ze1Puy8V"},"execution_count":null,"outputs":[]}]}