{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPiPemB3gQTpbI59V5b42Fc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Byte-Pair Encoding**"],"metadata":{"id":"ElDyqPsVJxMg"}},{"cell_type":"code","source":["# Import key modules\n","import numpy as np\n","from collections import Counter\n","from typing import Sequence, Tuple, Dict\n","import tiktoken # tokenizer for GPT-4\n","import requests\n","import re\n","import matplotlib.pyplot as plt"],"metadata":{"id":"86qRiCMNRyiL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Initialize Text"],"metadata":{"id":"YxNB-vbS2yxo"}},{"cell_type":"code","source":["from collections import Counter\n","\n","# texts with repetitions\n","# text = \"like liker love lovely hug hugs hugging heart\"\n","text = \"banana\"\n","\n","chars = list(set(text))\n","chars.sort()\n","\n","# Make a vocabulary\n","vocab = {ch: i for i, ch in enumerate(chars)}\n","print(f\"Vocabulary: \\n\\t {vocab}\")\n","\n","# Convert the text into a list of chracters\n","origtext = list(text)\n","\n","# # Create a dictionary with token pairs\n","\n","pairs = Counter(origtext[i] + origtext[i+1] for i in range(len(origtext) - 1))\n","print(f\"Text Pairs: \\n\\t {pairs}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7_psNiDNLMyN","executionInfo":{"status":"ok","timestamp":1763835482014,"user_tz":-330,"elapsed":5,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}},"outputId":"40f3a835-ab00-40f0-a740-479ec2ae78c0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulary: \n","\t {'a': 0, 'b': 1, 'n': 2}\n","Text Pairs: \n","\t Counter({'an': 2, 'na': 2, 'ba': 1})\n"]}]},{"cell_type":"code","source":["# find the most frequent pair\n","most_frequent_pair = pairs.most_common(1)[0][0]\n","print(f\"Most Frequent Pair: \\t \\'{most_frequent_pair}\\'\")\n","\n","# Add the most frequent pair to the vocabulary\n","vocab[most_frequent_pair] = len(vocab) + 1\n","print(vocab)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I38nHDeQL1gY","executionInfo":{"status":"ok","timestamp":1763835483136,"user_tz":-330,"elapsed":10,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}},"outputId":"775e32c6-fd81-4075-ead3-766251642979"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Most Frequent Pair: \t 'an'\n","{'a': 0, 'b': 1, 'n': 2, 'an': 4}\n"]}]},{"cell_type":"code","source":["# Create a new list of tokens with the pairs of most frequently occurring characters from the text\n","\n","new_text = []\n","\n","i = 0\n","\n","while i < len(origtext)-1:\n","        if origtext[i] + origtext[i+1] == most_frequent_pair:\n","          add_text = most_frequent_pair\n","          i += 2\n","        else:\n","          add_text = origtext[i]\n","          i += 1\n","\n","        new_text.append(add_text)\n","\n","print(f\"New Text: \\n\\t: {new_text}\")\n","\n"],"metadata":{"id":"G8Xu6DVLS9tC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763835484152,"user_tz":-330,"elapsed":8,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}},"outputId":"ac1808ff-f34f-4b3b-ec47-cf939406051c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["New Text: \n","\t: ['b', 'an', 'an']\n"]}]},{"cell_type":"code","source":["from collections import Counter\n","from typing import Tuple, List, Dict\n","\n","def bpe(text: str, vocab_size: int) -> Tuple[List[str], Dict[str, int]]:\n","    # Initialize vocabulary from characters\n","    chars = sorted(set(text))\n","    vocab: Dict[str, int] = {ch: i for i, ch in enumerate(chars)}\n","\n","    if len(vocab) >= vocab_size:\n","        return list(text), vocab\n","\n","    # Start with character-level tokens\n","    tokens: List[str] = list(text)\n","\n","    while len(vocab) < vocab_size:\n","        if len(tokens) < 2:\n","            break  # nothing to merge\n","\n","        # Step 1: find most frequent adjacent pair in current tokens\n","        pairs = Counter(tokens[i] + tokens[i+1] for i in range(len(tokens) - 1))\n","        most_frequent_pair, freq = pairs.most_common(1)[0]\n","\n","        # Step 2: add the pair to the vocabulary\n","        if most_frequent_pair not in vocab:\n","            vocab[most_frequent_pair] = len(vocab)\n","\n","        # Step 3: merge the pair in the token list\n","        new_tokens: List[str] = []\n","        i = 0\n","        while i < len(tokens):\n","            if i < len(tokens) - 1 and tokens[i] + tokens[i+1] == most_frequent_pair:\n","                new_tokens.append(most_frequent_pair)\n","                i += 2\n","            else:\n","                new_tokens.append(tokens[i])\n","                i += 1\n","\n","        tokens = new_tokens\n","\n","    return tokens, vocab\n"],"metadata":{"id":"MG4olmqnzYJG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text = \"like liker love lovely hug hugs hugging heart\"\n","vocab_size = 25\n","tokens, vocab = bpe(text, vocab_size)\n","print(f\"Final token : {tokens}\")\n","print(f\"Final vocabulary: {vocab}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JjZnr0uN45K8","executionInfo":{"status":"ok","timestamp":1763835487311,"user_tz":-330,"elapsed":4,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}},"outputId":"2675d7af-4c42-43f1-822f-52a4ffbd2731"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Final token : ['l', 'ike', ' l', 'ike', 'r', ' love', ' love', 'l', 'y', ' hug', ' hug', 's', ' hug', 'g', 'i', 'n', 'g', ' h', 'e', 'a', 'r', 't']\n","Final vocabulary: {' ': 0, 'a': 1, 'e': 2, 'g': 3, 'h': 4, 'i': 5, 'k': 6, 'l': 7, 'n': 8, 'o': 9, 'r': 10, 's': 11, 't': 12, 'u': 13, 'v': 14, 'y': 15, ' h': 16, ' l': 17, ' hu': 18, ' hug': 19, 'ik': 20, 'ike': 21, ' lo': 22, ' lov': 23, ' love': 24}\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"xevswgReqjJq"},"execution_count":null,"outputs":[]}]}