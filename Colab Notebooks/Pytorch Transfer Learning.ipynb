{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1ArqBKIfU1hSPMhRuFqZQnXpEl2qY5GWW","timestamp":1760854676027}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"501b21a5987a49b385f02f7c24dc5104":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8848ba5f89fc460c8d72df1bbdc044b1","IPY_MODEL_0196b6ec26b34570a308476926ed3bfd","IPY_MODEL_c3c52640ffc8417eb0440127a74766d9"],"layout":"IPY_MODEL_3968de53972c43419166cd72bab914f0"}},"8848ba5f89fc460c8d72df1bbdc044b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d18a3918d014a3fa0d06de69e39b9f9","placeholder":"​","style":"IPY_MODEL_7efff429dd9c4eb4ab7d0c1f6e70b955","value":"100%"}},"0196b6ec26b34570a308476926ed3bfd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_28dbf38f8eba4da2b6695fb7c340d239","max":5,"min":0,"orientation":"horizontal","style":"IPY_MODEL_796e6b2cc1f24bb69d8267c38ce27565","value":5}},"c3c52640ffc8417eb0440127a74766d9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_32c20f07b2df4af084810edb513e46aa","placeholder":"​","style":"IPY_MODEL_4099667df5954e24b3b3995eae3b814f","value":" 5/5 [00:09&lt;00:00,  1.60s/it]"}},"3968de53972c43419166cd72bab914f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d18a3918d014a3fa0d06de69e39b9f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7efff429dd9c4eb4ab7d0c1f6e70b955":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"28dbf38f8eba4da2b6695fb7c340d239":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"796e6b2cc1f24bb69d8267c38ce27565":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"32c20f07b2df4af084810edb513e46aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4099667df5954e24b3b3995eae3b814f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["## 1. Make predictions on the entire test dataset and plot a confusion matrix for the results of our model compared to the truth labels.\n","* **Note:** You will need to get the dataset and the trained model/retrain the model from notebook 06 to perform predictions.\n","* Check out [03. PyTorch Computer Vision section 10](https://www.learnpytorch.io/03_pytorch_computer_vision/#10-making-a-confusion-matrix-for-further-prediction-evaluation) for ideas."],"metadata":{"id":"nwmoMhW8IqSu"}},{"cell_type":"code","source":["# Import required libraries/code\n","import torch\n","import torchvision\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from torch import nn\n","from torchvision import transforms, datasets\n","\n","# Try to get torchinfo, install it if it doesn't work\n","try:\n","    from torchinfo import summary\n","except:\n","    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n","    !pip install -q torchinfo\n","    from torchinfo import summary\n","\n","# Try to import the going_modular directory, download it from GitHub if it doesn't work\n","try:\n","    from going_modular.going_modular import data_setup, engine\n","except:\n","    # Get the going_modular scripts\n","    print(\"[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\")\n","    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n","    !mv pytorch-deep-learning/going_modular .\n","    !rm -rf pytorch-deep-learning\n","    from going_modular.going_modular import data_setup, engine"],"metadata":{"id":"nqtAWBUJgaF1","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b51b21db-d2f2-4855-9144-2e886142733b","executionInfo":{"status":"ok","timestamp":1760854912507,"user_tz":-330,"elapsed":57272,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] Couldn't find torchinfo... installing it.\n","[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\n","Cloning into 'pytorch-deep-learning'...\n","remote: Enumerating objects: 4393, done.\u001b[K\n","remote: Total 4393 (delta 0), reused 0 (delta 0), pack-reused 4393 (from 1)\u001b[K\n","Receiving objects: 100% (4393/4393), 764.14 MiB | 28.97 MiB/s, done.\n","Resolving deltas: 100% (2656/2656), done.\n","Updating files: 100% (248/248), done.\n"]}]},{"cell_type":"code","source":["# Setup device agnostic code\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"O10_T_xSKJlf","outputId":"8e39cedd-c495-419f-b64d-8e3b0cf92b7a","executionInfo":{"status":"ok","timestamp":1760854918328,"user_tz":-330,"elapsed":24,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}}},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cuda'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["### Get data"],"metadata":{"id":"nrzg3TaSKLAh"}},{"cell_type":"code","source":["import os\n","import requests\n","import zipfile\n","\n","from pathlib import Path\n","\n","# Setup path to data folder\n","data_path = Path(\"data/\")\n","image_path = data_path / \"pizza_steak_sushi\"\n","\n","# If the image folder doesn't exist, download it and prepare it...\n","if image_path.is_dir():\n","    print(f\"{image_path} directory exists.\")\n","else:\n","    print(f\"Did not find {image_path} directory, creating one...\")\n","    image_path.mkdir(parents=True, exist_ok=True)\n","\n","    # Download pizza, steak, sushi data\n","    with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n","        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n","        print(\"Downloading pizza, steak, sushi data...\")\n","        f.write(request.content)\n","\n","    # Unzip pizza, steak, sushi data\n","    with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n","        print(\"Unzipping pizza, steak, sushi data...\")\n","        zip_ref.extractall(image_path)\n","\n","    # Remove .zip file\n","    os.remove(data_path / \"pizza_steak_sushi.zip\")\n","\n","# Setup Dirs\n","train_dir = image_path / \"train\"\n","test_dir = image_path / \"test\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lt_CNQ4rKPmg","outputId":"388874e9-6a50-4181-b198-e9af9684b5bb","executionInfo":{"status":"ok","timestamp":1760854922696,"user_tz":-330,"elapsed":1055,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Did not find data/pizza_steak_sushi directory, creating one...\n","Downloading pizza, steak, sushi data...\n","Unzipping pizza, steak, sushi data...\n"]}]},{"cell_type":"markdown","source":["### Prepare data"],"metadata":{"id":"PGaMWWaoKQlM"}},{"cell_type":"code","source":["# Create a transforms pipeline\n","simple_transform = transforms.Compose([\n","    transforms.Resize((224, 224)), # 1. Reshape all images to 224x224 (though some models may require different sizes)\n","    transforms.ToTensor(), # 2. Turn image values to between 0 & 1\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], # 3. A mean of [0.485, 0.456, 0.406] (across each colour channel)\n","                         std=[0.229, 0.224, 0.225]) # 4. A standard deviation of [0.229, 0.224, 0.225] (across each colour channel),\n","])"],"metadata":{"id":"VNIQNEQVKVXu","executionInfo":{"status":"ok","timestamp":1760854930936,"user_tz":-330,"elapsed":4,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Create training and testing DataLoader's as well as get a list of class names\n","train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n","                                                                               test_dir=test_dir,\n","                                                                               transform=simple_transform, # resize, convert images to between 0 & 1 and normalize them\n","                                                                               batch_size=32) # set mini-batch size to 32\n","\n","train_dataloader, test_dataloader, class_names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Njd5lHTcKW23","outputId":"ccac0e61-4dea-4097-bbf2-c5ed0d894bc9","executionInfo":{"status":"ok","timestamp":1760854941651,"user_tz":-330,"elapsed":16,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}}},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<torch.utils.data.dataloader.DataLoader at 0x780de3856b10>,\n"," <torch.utils.data.dataloader.DataLoader at 0x780dd89de450>,\n"," ['pizza', 'steak', 'sushi'])"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["### Get and prepare a pretrained model"],"metadata":{"id":"Ciw2DiRHKaSE"}},{"cell_type":"code","source":["# Setup the model with pretrained weights and send it to the target device\n","model_0 = torchvision.models.efficientnet_b0(pretrained=True).to(device)\n","#model_0 # uncomment to output (it's very long)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"snUuRXd8Kdk5","outputId":"c32608f7-241e-4763-b81b-4c9a6dad285c","executionInfo":{"status":"ok","timestamp":1760854948339,"user_tz":-330,"elapsed":564,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20.5M/20.5M [00:00<00:00, 156MB/s]\n"]}]},{"cell_type":"code","source":["# Freeze all base layers in the \"features\" section of the model (the feature extractor) by setting requires_grad=False\n","for param in model_0.features.parameters():\n","    param.requires_grad = False"],"metadata":{"id":"IbRhGvy_KeVL","executionInfo":{"status":"ok","timestamp":1760854965592,"user_tz":-330,"elapsed":11,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Set the manual seeds\n","torch.manual_seed(42)\n","torch.cuda.manual_seed(42)\n","\n","# Get the length of class_names (one output unit for each class)\n","output_shape = len(class_names)\n","\n","# Recreate the classifier layer and seed it to the target device\n","model_0.classifier = torch.nn.Sequential(\n","    torch.nn.Dropout(p=0.2, inplace=True),\n","    torch.nn.Linear(in_features=1280,\n","                    out_features=output_shape, # same number of output units as our number of classes\n","                    bias=True)).to(device)"],"metadata":{"id":"G1-6xV3ZKeSX","executionInfo":{"status":"ok","timestamp":1760854969724,"user_tz":-330,"elapsed":14,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["### Train model"],"metadata":{"id":"XQFaXX8CKePi"}},{"cell_type":"code","source":["# Define loss and optimizer\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model_0.parameters(), lr=0.001)"],"metadata":{"id":"exxU79eaKeM6","executionInfo":{"status":"ok","timestamp":1760854983953,"user_tz":-330,"elapsed":8,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Set the random seeds\n","torch.manual_seed(42)\n","torch.cuda.manual_seed(42)\n","\n","# Start the timer\n","from timeit import default_timer as timer\n","start_time = timer()\n","\n","# Setup training and save the results\n","model_0_results = engine.train(model=model_0,\n","                       train_dataloader=train_dataloader,\n","                       test_dataloader=test_dataloader,\n","                       optimizer=optimizer,\n","                       loss_fn=loss_fn,\n","                       epochs=5,\n","                       device=device)\n","\n","# End the timer and print out how long it took\n","end_time = timer()\n","print(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":156,"referenced_widgets":["501b21a5987a49b385f02f7c24dc5104","8848ba5f89fc460c8d72df1bbdc044b1","0196b6ec26b34570a308476926ed3bfd","c3c52640ffc8417eb0440127a74766d9","3968de53972c43419166cd72bab914f0","5d18a3918d014a3fa0d06de69e39b9f9","7efff429dd9c4eb4ab7d0c1f6e70b955","28dbf38f8eba4da2b6695fb7c340d239","796e6b2cc1f24bb69d8267c38ce27565","32c20f07b2df4af084810edb513e46aa","4099667df5954e24b3b3995eae3b814f"]},"id":"ComVkVtuKeKG","outputId":"e88e32c2-9bff-412d-9dd7-b04d36da8a68","executionInfo":{"status":"ok","timestamp":1760854995313,"user_tz":-330,"elapsed":9126,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}}},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/5 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"501b21a5987a49b385f02f7c24dc5104"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 1 | train_loss: 1.0895 | train_acc: 0.4414 | test_loss: 0.9202 | test_acc: 0.5085\n","Epoch: 2 | train_loss: 0.8682 | train_acc: 0.7734 | test_loss: 0.8022 | test_acc: 0.7434\n","Epoch: 3 | train_loss: 0.7771 | train_acc: 0.7812 | test_loss: 0.7399 | test_acc: 0.7737\n","Epoch: 4 | train_loss: 0.7249 | train_acc: 0.7422 | test_loss: 0.6472 | test_acc: 0.8864\n","Epoch: 5 | train_loss: 0.6445 | train_acc: 0.7812 | test_loss: 0.6244 | test_acc: 0.8968\n","[INFO] Total training time: 9.103 seconds\n"]}]},{"cell_type":"markdown","source":["### Make predictions on the entire test dataset with the model"],"metadata":{"id":"xFS4lE_IKyE_"}},{"cell_type":"code","source":["# TODO"],"metadata":{"id":"DwZuCluFu375","executionInfo":{"status":"ok","timestamp":1760855007704,"user_tz":-330,"elapsed":41,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["### Make a confusion matrix with the test preds and the truth labels"],"metadata":{"id":"Mb2bQ1b5K2WP"}},{"cell_type":"markdown","source":["Need the following libraries to make a confusion matrix:\n","* torchmetrics - https://torchmetrics.readthedocs.io/en/stable/\n","* mlxtend - http://rasbt.github.io/mlxtend/"],"metadata":{"id":"5I2jpYAcM07s"}},{"cell_type":"code","source":["# See if torchmetrics exists, if not, install it\n","try:\n","    import torchmetrics, mlxtend\n","    print(f\"mlxtend version: {mlxtend.__version__}\")\n","    assert int(mlxtend.__version__.split(\".\")[1]) >= 19, \"mlxtend verison should be 0.19.0 or higher\"\n","except:\n","    !pip install -q torchmetrics -U mlxtend # <- Note: If you're using Google Colab, this may require restarting the runtime\n","    import torchmetrics, mlxtend\n","    print(f\"mlxtend version: {mlxtend.__version__}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qcKYZGWuK2P8","outputId":"6be880d1-21b8-43b1-d129-3b0ea0d0167e","executionInfo":{"status":"ok","timestamp":1760855019954,"user_tz":-330,"elapsed":9702,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}}},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/983.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m983.0/983.2 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hmlxtend version: 0.23.4\n"]}]},{"cell_type":"code","source":["# Import mlxtend upgraded version\n","import mlxtend\n","print(mlxtend.__version__)\n","assert int(mlxtend.__version__.split(\".\")[1]) >= 19 # should be version 0.19.0 or higher"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QOYVew4xMxgI","outputId":"dd8e3878-e3c1-4f6e-baba-cea0549127f8","executionInfo":{"status":"ok","timestamp":1760855026323,"user_tz":-330,"elapsed":21,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}}},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["0.23.4\n"]}]},{"cell_type":"code","source":["# TODO"],"metadata":{"id":"_5LU9-5Xu7dP","executionInfo":{"status":"ok","timestamp":1760855028105,"user_tz":-330,"elapsed":11,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["## 2. Get the \"most wrong\" of the predictions on the test dataset and plot the 5 \"most wrong\" images. You can do this by:\n","* Predicting across all of the test dataset, storing the labels and predicted probabilities.\n","* Sort the predictions by *wrong prediction* and then *descending predicted probabilities*, this will give you the wrong predictions with the *highest* prediction probabilities, in other words, the \"most wrong\".\n","* Plot the top 5 \"most wrong\" images, why do you think the model got these wrong?\n","\n","You'll want to:\n","* Create a DataFrame with sample, label, prediction, pred prob\n","* Sort DataFrame by correct (does label == prediction)\n","* Sort DataFrame by pred prob (descending)\n","* Plot the top 5 \"most wrong\" image predictions"],"metadata":{"id":"YqlStPo-gbrF"}},{"cell_type":"code","source":["# TODO"],"metadata":{"id":"cHtMeYHuvDwy","executionInfo":{"status":"ok","timestamp":1760855032045,"user_tz":-330,"elapsed":9,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["## 3. Predict on your own image of pizza/steak/sushi - how does the model go? What happens if you predict on an image that isn't pizza/steak/sushi?\n","* Here you can get an image from a website like http://www.unsplash.com to try it out or you can upload your own."],"metadata":{"id":"1IvuTskxgjaw"}},{"cell_type":"code","source":["# TODO: Get an image of pizza/steak/sushi\n"],"metadata":{"id":"C16glgVFglmG","executionInfo":{"status":"ok","timestamp":1760855034605,"user_tz":-330,"elapsed":41,"user":{"displayName":"Anirban Guha","userId":"10209519538744786819"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# TODO: Get an image of not pizza/steak/sushi\n"],"metadata":{"id":"clA_KmihVYyA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4. Train the model from section 4  in notebook 06 part 3 for longer (10 epochs should do), what happens to the performance?\n","\n","* See the model in notebook 06 part 3 for reference: https://www.learnpytorch.io/06_pytorch_transfer_learning/#3-getting-a-pretrained-model"],"metadata":{"id":"Vzvi8GprgmJ0"}},{"cell_type":"code","source":["# TODO: Recreate a new model\n"],"metadata":{"id":"kIKg53Jna-Rt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: Train the model for 10 epochs"],"metadata":{"id":"JhGT9igPgoF5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5. Train the model from section 4 above with more data, say 20% of the images from Food101 of Pizza, Steak and Sushi images.\n","* You can find the [20% Pizza, Steak, Sushi dataset](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/data/pizza_steak_sushi_20_percent.zip) on the course GitHub. It was created with the notebook [`extras/04_custom_data_creation.ipynb`](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/04_custom_data_creation.ipynb).\n"],"metadata":{"id":"_oRrWPZTgoqL"}},{"cell_type":"markdown","source":["### Get 20% data"],"metadata":{"id":"VxyMMnUbgvw2"}},{"cell_type":"code","source":["import os\n","import requests\n","import zipfile\n","\n","from pathlib import Path\n","\n","# Setup path to data folder\n","data_path = Path(\"data/\")\n","image_path = data_path / \"pizza_steak_sushi_20_percent\"\n","image_data_zip_path = \"pizza_steak_sushi_20_percent.zip\"\n","\n","# If the image folder doesn't exist, download it and prepare it...\n","if image_path.is_dir():\n","    print(f\"{image_path} directory exists.\")\n","else:\n","    print(f\"Did not find {image_path} directory, creating one...\")\n","    image_path.mkdir(parents=True, exist_ok=True)\n","\n","    # Download pizza, steak, sushi data\n","    with open(data_path / image_data_zip_path, \"wb\") as f:\n","        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip\")\n","        print(\"Downloading pizza, steak, sushi data...\")\n","        f.write(request.content)\n","\n","    # Unzip pizza, steak, sushi data\n","    with zipfile.ZipFile(data_path / image_data_zip_path, \"r\") as zip_ref:\n","        print(\"Unzipping pizza, steak, sushi 20% data...\")\n","        zip_ref.extractall(image_path)\n","\n","    # Remove .zip file\n","    os.remove(data_path / image_data_zip_path)\n","\n","# Setup Dirs\n","train_dir_20_percent = image_path / \"train\"\n","test_dir_20_percent = image_path / \"test\"\n","\n","train_dir_20_percent, test_dir_20_percent"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U_fdu5m2eKT9","outputId":"121c61f3-f505-4302-b3b9-8b8bae5b5e1d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Did not find data/pizza_steak_sushi_20_percent directory, creating one...\n","Downloading pizza, steak, sushi data...\n","Unzipping pizza, steak, sushi 20% data...\n"]},{"output_type":"execute_result","data":{"text/plain":["(PosixPath('data/pizza_steak_sushi_20_percent/train'),\n"," PosixPath('data/pizza_steak_sushi_20_percent/test'))"]},"metadata":{},"execution_count":33}]},{"cell_type":"markdown","source":["### Create DataLoaders"],"metadata":{"id":"SQj7eFdSe4Fv"}},{"cell_type":"code","source":["# Create a transforms pipeline\n","simple_transform = transforms.Compose([\n","    transforms.Resize((224, 224)), # 1. Reshape all images to 224x224 (though some models may require different sizes)\n","    transforms.ToTensor(), # 2. Turn image values to between 0 & 1\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], # 3. A mean of [0.485, 0.456, 0.406] (across each colour channel)\n","                         std=[0.229, 0.224, 0.225]) # 4. A standard deviation of [0.229, 0.224, 0.225] (across each colour channel),\n","])"],"metadata":{"id":"TEG_k785e7Jw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create training and testing DataLoader's as well as get a list of class names\n","train_dataloader_20_percent, test_dataloader_20_percent, class_names = data_setup.create_dataloaders(train_dir=train_dir_20_percent,\n","                                                                                                     test_dir=test_dir_20_percent,\n","                                                                                                     transform=simple_transform, # resize, convert images to between 0 & 1 and normalize them\n","                                                                                                     batch_size=32) # set mini-batch size to 32\n","\n","train_dataloader_20_percent, test_dataloader_20_percent, class_names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"82x7LnQJe7H5","outputId":"342fd4e7-0656-495a-aee0-0d23be130438"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<torch.utils.data.dataloader.DataLoader at 0x7f5ede28e390>,\n"," <torch.utils.data.dataloader.DataLoader at 0x7f5ede28e210>,\n"," ['pizza', 'steak', 'sushi'])"]},"metadata":{},"execution_count":35}]},{"cell_type":"markdown","source":["### Get a pretrained model"],"metadata":{"id":"qROl77sKfIOd"}},{"cell_type":"code","source":["# TODO"],"metadata":{"id":"PHWNZ6yDvpR8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Train a model with 20% of the data"],"metadata":{"id":"UqffJfOIfp3T"}},{"cell_type":"code","source":["# TODO"],"metadata":{"id":"wXpYOYeTvp7a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 6. Try a different model from [`torchvision.models`](https://pytorch.org/vision/stable/models.html) on the Pizza, Steak, Sushi data, how does this model perform?\n","* You'll have to change the size of the classifier layer to suit our problem.\n","* You may want to try an EfficientNet with a higher number than our B0, perhaps `torchvision.models.efficientnet_b2()`?\n","  * **Note:** Depending on the model you use you will have to prepare/transform the data in a certain way."],"metadata":{"id":"Ibj4UPjRgvly"}},{"cell_type":"code","source":["# TODO"],"metadata":{"id":"3FQ8tL7El7eO"},"execution_count":null,"outputs":[]}]}